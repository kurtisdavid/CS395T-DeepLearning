{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "They only mean center so we found the mean pixel value of faces and normalize with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5089547997389491],\n",
    "                                     std=[1])])\n",
    "allImages = datasets.ImageFolder(root='./training',transform = data_transform)\n",
    "label_mapping = torch.FloatTensor([float(clazz) for clazz in allImages.classes])\n",
    "# label_mappin\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it output from [0,1] rather than [1900,2010]\n",
    "label_mapping_scaled = (label_mapping - label_mapping.min())/(label_mapping.max() - label_mapping.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(allImages,batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_layers, final_output, bottleneck = False):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.conv_params = {'kernel_size': 3, 'padding': 1}\n",
    "        self.width = 186\n",
    "        self.height = 171\n",
    "        self.layer_dict = {\n",
    "            18: [2,2,2,2],\n",
    "            34: [3,4,6,3]\n",
    "        }\n",
    "        self.layers = {}\n",
    "        \n",
    "        in_channels = 1\n",
    "        out_channels = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 7, stride = 2, padding = 3),\n",
    "            nn.BatchNorm2d(num_features = out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1, dilation = 1)\n",
    "        )\n",
    "        self.width = self.width / 2\n",
    "        self.width = math.floor( (self.width - 1) / 2 + 1 )\n",
    "        self.height = self.height / 2\n",
    "        self.height = math.floor( (self.height - 1) / 2 + 1)\n",
    "        print(\"Height is now:\", self.height, \"Width is now:\", self.width)\n",
    "        \n",
    "        \n",
    "        in_channels = 64\n",
    "        \n",
    "        num_repeat = self.layer_dict[n_layers]\n",
    "        for i in range(2,6):\n",
    "            self.res_layer = i\n",
    "            # [ [blocks], transition ]\n",
    "            self.layers[self.res_layer] = [[], None]\n",
    "            for j in range(num_repeat[i-2]):\n",
    "                self.create_block(in_channels, out_channels, j, bottleneck)\n",
    "                if j == 0:\n",
    "                    self.add_transition()\n",
    "                in_channels = out_channels\n",
    "            out_channels = out_channels * 2\n",
    "            \n",
    "        # global average pooling\n",
    "        self.global_avg = nn.AvgPool2d(kernel_size = (self.width,self.height), stride = 1)\n",
    "        # fully connected to final\n",
    "        self.output = nn.Linear(in_channels,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def create_block(self, in_channels, out_channels, block_num, bottleneck):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, stride = 1, **self.conv_params),\n",
    "            nn.BatchNorm2d(num_features = out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, stride = 2 if block_num == 0 else 1, **self.conv_params),\n",
    "            nn.BatchNorm2d(num_features = out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.add_module(\"conv\" + str(self.res_layer) + \"_\" + str(block_num), block)\n",
    "        self.layers[self.res_layer][0].append(block)\n",
    "        print(\"Added\", \"conv\" + str(self.res_layer) + \"_\" + str(block_num), \"input: \" + str(in_channels), \"output: \" + str(out_channels))\n",
    "        \n",
    "        if block_num == 0:\n",
    "            self.height = math.floor( (self.height - 1) / 2 + 1)\n",
    "            self.width = math.floor( (self.width - 1) / 2 + 1)\n",
    "            print(\"Height is now:\", self.height, \"Width is now:\", self.width)\n",
    "        \n",
    "    \n",
    "    def add_transition(self):\n",
    "        transition = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        )\n",
    "        self.add_module(\"transition\"+ str(self.res_layer), transition)\n",
    "        self.layers[self.res_layer][1] = transition\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # go through conv1\n",
    "        X = self.conv1(X)\n",
    "        # go through residuals\n",
    "        for i in range(2,self.res_layer + 1):\n",
    "            layers,transition = self.layers[i]\n",
    "            for j,layer in enumerate(layers):\n",
    "                if j == 0:\n",
    "                    \n",
    "                    pool = transition(X)\n",
    "                    # dimension transition\n",
    "                    if i > 2:\n",
    "                        padding = (0,0,0,0,pool.shape[1]//2,pool.shape[1]//2,0,0)\n",
    "                        pool = nn.functional.pad(pool,padding)\n",
    "                    X = layer(X)\n",
    "                    X = X + pool\n",
    "                else:\n",
    "                    X = layer(X)\n",
    "        X = self.global_avg(X)\n",
    "        X = X.view(X.shape[0],-1)\n",
    "        X = self.output(X)\n",
    "        return X.view(-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height is now: 43 Width is now: 47\n",
      "Added conv2_0 input: 64 output: 64\n",
      "Height is now: 22 Width is now: 24\n",
      "Added conv2_1 input: 64 output: 64\n",
      "Added conv2_2 input: 64 output: 64\n",
      "Added conv3_0 input: 64 output: 128\n",
      "Height is now: 11 Width is now: 12\n",
      "Added conv3_1 input: 128 output: 128\n",
      "Added conv3_2 input: 128 output: 128\n",
      "Added conv3_3 input: 128 output: 128\n",
      "Added conv4_0 input: 128 output: 256\n",
      "Height is now: 6 Width is now: 6\n",
      "Added conv4_1 input: 256 output: 256\n",
      "Added conv4_2 input: 256 output: 256\n",
      "Added conv4_3 input: 256 output: 256\n",
      "Added conv4_4 input: 256 output: 256\n",
      "Added conv4_5 input: 256 output: 256\n",
      "Added conv5_0 input: 256 output: 512\n",
      "Height is now: 3 Width is now: 3\n",
      "Added conv5_1 input: 512 output: 512\n",
      "Added conv5_2 input: 512 output: 512\n"
     ]
    }
   ],
   "source": [
    "resnet34 = ResNet(34,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21112705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "Epoch 0: Training Loss: 0.164\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "Epoch 1: Training Loss: 0.104\n",
      "375\n",
      "400\n",
      "425\n",
      "450\n",
      "475\n",
      "500\n",
      "525\n",
      "Epoch 2: Training Loss: 0.090\n",
      "550\n",
      "575\n",
      "600\n",
      "625\n",
      "650\n",
      "675\n",
      "700\n",
      "Epoch 3: Training Loss: 0.084\n",
      "725\n",
      "750\n",
      "775\n",
      "800\n",
      "825\n",
      "850\n",
      "875\n",
      "Epoch 4: Training Loss: 0.078\n",
      "900\n",
      "925\n",
      "950\n",
      "975\n",
      "1000\n",
      "1025\n",
      "1050\n",
      "Epoch 5: Training Loss: 0.071\n",
      "1075\n",
      "1100\n",
      "1125\n",
      "1150\n",
      "1175\n",
      "1200\n",
      "1225\n",
      "1250\n",
      "Epoch 6: Training Loss: 0.071\n",
      "1275\n",
      "1300\n",
      "1325\n",
      "1350\n",
      "1375\n",
      "1400\n",
      "1425\n",
      "Epoch 7: Training Loss: 0.067\n",
      "1450\n",
      "1475\n",
      "1500\n",
      "1525\n",
      "1550\n",
      "1575\n",
      "1600\n",
      "Epoch 8: Training Loss: 0.066\n",
      "1625\n",
      "1650\n",
      "1675\n",
      "1700\n",
      "1725\n",
      "1750\n",
      "1775\n",
      "Epoch 9: Training Loss: 0.061\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(resnet18.parameters(),lr = 0.01, betas = (0.9,0.999))\n",
    "loss_metric = nn.L1Loss()\n",
    "n_epochs = 10\n",
    "iteration = 0\n",
    "for e in range(n_epochs):\n",
    "    losses = []\n",
    "    for batch_input, batch_labels in dataloader:\n",
    "        if iteration % 25 == 0:\n",
    "            print(iteration)\n",
    "        # make sure to zero out gradient\n",
    "        resnet18.zero_grad()\n",
    "        \n",
    "        # move to gpu + get correct labels\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_labels = label_mapping_scaled[batch_labels].to(device)\n",
    "        \n",
    "        loss = loss_metric(resnet18(batch_input),batch_labels)\n",
    "        losses.append(loss.data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        iteration += 1\n",
    "#         break\n",
    "    print(\"Epoch %d: Training Loss: %0.3f\" % (e,np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
