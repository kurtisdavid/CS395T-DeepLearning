{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "They only mean center so we found the mean pixel value of faces and normalize with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5089547997389491],\n",
    "                                     std=[1])])\n",
    "allImages = datasets.ImageFolder(root='./training',transform = data_transform)\n",
    "label_mapping = torch.FloatTensor([float(clazz) for clazz in allImages.classes])\n",
    "# label_mappin\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it output from [0,1] rather than [1900,2010]\n",
    "label_mapping_scaled = (label_mapping - label_mapping.min())/(label_mapping.max() - label_mapping.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(allImages,batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_layers, final_output, bottleneck = False):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.conv_params = {'kernel_size': 3, 'padding': 1}\n",
    "        self.width = 186\n",
    "        self.height = 171\n",
    "        self.layer_dict = {\n",
    "            18: [2,2,2,2],\n",
    "            34: [3,4,6,3]\n",
    "        }\n",
    "        self.layers = {}\n",
    "        \n",
    "        in_channels = 1\n",
    "        out_channels = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 7, stride = 2, padding = 3),\n",
    "            nn.BatchNorm2d(num_features = out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1, dilation = 1)\n",
    "        )\n",
    "        self.width = self.width / 2\n",
    "        self.width = math.floor( (self.width - 1) / 2 + 1 )\n",
    "        self.height = self.height / 2\n",
    "        self.height = math.floor( (self.height - 1) / 2 + 1)\n",
    "        print(\"Height is now:\", self.height, \"Width is now:\", self.width)\n",
    "        \n",
    "        \n",
    "        in_channels = 64\n",
    "        \n",
    "        num_repeat = self.layer_dict[n_layers]\n",
    "        for i in range(2,6):\n",
    "            self.res_layer = i\n",
    "            # [ [blocks], transition ]\n",
    "            self.layers[self.res_layer] = [[], None]\n",
    "            for j in range(num_repeat[i-2]):\n",
    "                self.create_block(in_channels, out_channels, j, bottleneck)\n",
    "                if j == 0:\n",
    "                    self.add_transition()\n",
    "                in_channels = out_channels\n",
    "            out_channels = out_channels * 2\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # global average pooling\n",
    "        self.global_avg = nn.AvgPool2d(kernel_size = (self.width,self.height), stride = 1)\n",
    "        # fully connected to final\n",
    "        self.output = nn.Linear(in_channels,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def create_block(self, in_channels, out_channels, block_num, bottleneck):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, stride = 1, **self.conv_params),\n",
    "            nn.BatchNorm2d(num_features = out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride = 2 if block_num == 0 else 1, **self.conv_params),\n",
    "            nn.BatchNorm2d(num_features = out_channels)\n",
    "        )\n",
    "        self.add_module(\"conv\" + str(self.res_layer) + \"_\" + str(block_num), block)\n",
    "        self.layers[self.res_layer][0].append(block)\n",
    "        print(\"Added\", \"conv\" + str(self.res_layer) + \"_\" + str(block_num), \"input: \" + str(in_channels), \"output: \" + str(out_channels))\n",
    "        \n",
    "        if block_num == 0:\n",
    "            self.height = math.floor( (self.height - 1) / 2 + 1)\n",
    "            self.width = math.floor( (self.width - 1) / 2 + 1)\n",
    "            print(\"Height is now:\", self.height, \"Width is now:\", self.width)\n",
    "        \n",
    "    \n",
    "    def add_transition(self):\n",
    "        transition = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        )\n",
    "        self.add_module(\"transition\"+ str(self.res_layer), transition)\n",
    "        self.layers[self.res_layer][1] = transition\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # go through conv1\n",
    "        X = self.conv1(X)\n",
    "        # go through residuals\n",
    "        for i in range(2,self.res_layer + 1):\n",
    "            layers,transition = self.layers[i]\n",
    "            for j,layer in enumerate(layers):\n",
    "                pool = X\n",
    "                if j == 0:          \n",
    "                    pool = transition(X)\n",
    "                    # dimension transition\n",
    "                    if i > 2:\n",
    "                        padding = (0,0,0,0,pool.shape[1]//2,pool.shape[1]//2,0,0)\n",
    "                        pool = nn.functional.pad(pool,padding)\n",
    "                X = layer(X) + pool\n",
    "                X = self.relu(X)\n",
    "        X = self.global_avg(X)\n",
    "        X = X.view(X.shape[0],-1)\n",
    "        X = self.output(X)\n",
    "        return X.view(-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height is now: 43 Width is now: 47\n",
      "Added conv2_0 input: 64 output: 64\n",
      "Height is now: 22 Width is now: 24\n",
      "Added conv2_1 input: 64 output: 64\n",
      "Added conv2_2 input: 64 output: 64\n",
      "Added conv3_0 input: 64 output: 128\n",
      "Height is now: 11 Width is now: 12\n",
      "Added conv3_1 input: 128 output: 128\n",
      "Added conv3_2 input: 128 output: 128\n",
      "Added conv3_3 input: 128 output: 128\n",
      "Added conv4_0 input: 128 output: 256\n",
      "Height is now: 6 Width is now: 6\n",
      "Added conv4_1 input: 256 output: 256\n",
      "Added conv4_2 input: 256 output: 256\n",
      "Added conv4_3 input: 256 output: 256\n",
      "Added conv4_4 input: 256 output: 256\n",
      "Added conv4_5 input: 256 output: 256\n",
      "Added conv5_0 input: 256 output: 512\n",
      "Height is now: 3 Width is now: 3\n",
      "Added conv5_1 input: 512 output: 512\n",
      "Added conv5_2 input: 512 output: 512\n"
     ]
    }
   ],
   "source": [
    "resnet34 = ResNet(34,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21112705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(resnet34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "Epoch 0: Training Loss: 0.162\n",
      "200\n",
      "300\n",
      "Epoch 1: Training Loss: 0.108\n",
      "400\n",
      "500\n",
      "Epoch 2: Training Loss: 0.095\n",
      "600\n",
      "700\n",
      "Epoch 3: Training Loss: 0.087\n",
      "800\n",
      "Epoch 4: Training Loss: 0.080\n",
      "900\n",
      "1000\n",
      "Epoch 5: Training Loss: 0.074\n",
      "1100\n",
      "1200\n",
      "Epoch 6: Training Loss: 0.074\n",
      "1300\n",
      "1400\n",
      "Epoch 7: Training Loss: 0.064\n",
      "1500\n",
      "1600\n",
      "Epoch 8: Training Loss: 0.063\n",
      "1700\n",
      "Epoch 9: Training Loss: 0.057\n",
      "1800\n",
      "1900\n",
      "Epoch 10: Training Loss: 0.055\n",
      "2000\n",
      "2100\n",
      "Epoch 11: Training Loss: 0.052\n",
      "2200\n",
      "2300\n",
      "Epoch 12: Training Loss: 0.049\n",
      "2400\n",
      "2500\n",
      "Epoch 13: Training Loss: 0.047\n",
      "2600\n",
      "Epoch 14: Training Loss: 0.044\n",
      "2700\n",
      "2800\n",
      "Epoch 15: Training Loss: 0.042\n",
      "2900\n",
      "3000\n",
      "Epoch 16: Training Loss: 0.040\n",
      "3100\n",
      "3200\n",
      "Epoch 17: Training Loss: 0.043\n",
      "3300\n",
      "3400\n",
      "Epoch 18: Training Loss: 0.039\n",
      "3500\n",
      "Epoch 19: Training Loss: 0.035\n",
      "3600\n",
      "3700\n",
      "Epoch 20: Training Loss: 0.034\n",
      "3800\n",
      "3900\n",
      "Epoch 21: Training Loss: 0.033\n",
      "4000\n",
      "4100\n",
      "Epoch 22: Training Loss: 0.033\n",
      "4200\n",
      "Epoch 23: Training Loss: 0.031\n",
      "4300\n",
      "4400\n",
      "Epoch 24: Training Loss: 0.030\n",
      "4500\n",
      "4600\n",
      "Epoch 25: Training Loss: 0.031\n",
      "4700\n",
      "4800\n",
      "Epoch 26: Training Loss: 0.027\n",
      "4900\n",
      "5000\n",
      "Epoch 27: Training Loss: 0.025\n",
      "5100\n",
      "Epoch 28: Training Loss: 0.030\n",
      "5200\n",
      "5300\n",
      "Epoch 29: Training Loss: 0.030\n",
      "5400\n",
      "5500\n",
      "Epoch 30: Training Loss: 0.025\n",
      "5600\n",
      "5700\n",
      "Epoch 31: Training Loss: 0.022\n",
      "5800\n",
      "5900\n",
      "Epoch 32: Training Loss: 0.022\n",
      "6000\n",
      "Epoch 33: Training Loss: 0.022\n",
      "6100\n",
      "6200\n",
      "Epoch 34: Training Loss: 0.021\n",
      "6300\n",
      "6400\n",
      "Epoch 35: Training Loss: 0.024\n",
      "6500\n",
      "6600\n",
      "Epoch 36: Training Loss: 0.023\n",
      "6700\n",
      "6800\n",
      "Epoch 37: Training Loss: 0.021\n",
      "6900\n",
      "Epoch 38: Training Loss: 0.021\n",
      "7000\n",
      "7100\n",
      "Epoch 39: Training Loss: 0.019\n",
      "7200\n",
      "7300\n",
      "Epoch 40: Training Loss: 0.025\n",
      "7400\n",
      "7500\n",
      "Epoch 41: Training Loss: 0.021\n",
      "7600\n",
      "Epoch 42: Training Loss: 0.017\n",
      "7700\n",
      "7800\n",
      "Epoch 43: Training Loss: 0.018\n",
      "7900\n",
      "8000\n",
      "Epoch 44: Training Loss: 0.016\n",
      "8100\n",
      "8200\n",
      "Epoch 45: Training Loss: 0.020\n",
      "8300\n",
      "8400\n",
      "Epoch 46: Training Loss: 0.019\n",
      "8500\n",
      "Epoch 47: Training Loss: 0.018\n",
      "8600\n",
      "8700\n",
      "Epoch 48: Training Loss: 0.016\n",
      "8800\n",
      "8900\n",
      "Epoch 49: Training Loss: 0.014\n",
      "9000\n",
      "9100\n",
      "Epoch 50: Training Loss: 0.018\n",
      "9200\n",
      "9300\n",
      "Epoch 51: Training Loss: 0.018\n",
      "9400\n",
      "Epoch 52: Training Loss: 0.016\n",
      "9500\n",
      "9600\n",
      "Epoch 53: Training Loss: 0.015\n",
      "9700\n",
      "9800\n",
      "Epoch 54: Training Loss: 0.015\n",
      "9900\n",
      "10000\n",
      "Epoch 55: Training Loss: 0.015\n",
      "10100\n",
      "10200\n",
      "Epoch 56: Training Loss: 0.015\n",
      "10300\n",
      "Epoch 57: Training Loss: 0.013\n",
      "10400\n",
      "10500\n",
      "Epoch 58: Training Loss: 0.022\n",
      "10600\n",
      "10700\n",
      "Epoch 59: Training Loss: 0.014\n",
      "10800\n",
      "10900\n",
      "Epoch 60: Training Loss: 0.014\n",
      "11000\n",
      "Epoch 61: Training Loss: 0.013\n",
      "11100\n",
      "11200\n",
      "Epoch 62: Training Loss: 0.013\n",
      "11300\n",
      "11400\n",
      "Epoch 63: Training Loss: 0.013\n",
      "11500\n",
      "11600\n",
      "Epoch 64: Training Loss: 0.014\n",
      "11700\n",
      "11800\n",
      "Epoch 65: Training Loss: 0.012\n",
      "11900\n",
      "Epoch 66: Training Loss: 0.018\n",
      "12000\n",
      "12100\n",
      "Epoch 67: Training Loss: 0.018\n",
      "12200\n",
      "12300\n",
      "Epoch 68: Training Loss: 0.013\n",
      "12400\n",
      "12500\n",
      "Epoch 69: Training Loss: 0.013\n",
      "12600\n",
      "12700\n",
      "Epoch 70: Training Loss: 0.012\n",
      "12800\n",
      "Epoch 71: Training Loss: 0.011\n",
      "12900\n",
      "13000\n",
      "Epoch 72: Training Loss: 0.015\n",
      "13100\n",
      "13200\n",
      "Epoch 73: Training Loss: 0.011\n",
      "13300\n",
      "13400\n",
      "Epoch 74: Training Loss: 0.010\n",
      "13500\n",
      "13600\n",
      "Epoch 75: Training Loss: 0.010\n",
      "13700\n",
      "Epoch 76: Training Loss: 0.011\n",
      "13800\n",
      "13900\n",
      "Epoch 77: Training Loss: 0.010\n",
      "14000\n",
      "14100\n",
      "Epoch 78: Training Loss: 0.012\n",
      "14200\n",
      "14300\n",
      "Epoch 79: Training Loss: 0.010\n",
      "14400\n",
      "Epoch 80: Training Loss: 0.009\n",
      "14500\n",
      "14600\n",
      "Epoch 81: Training Loss: 0.010\n",
      "14700\n",
      "14800\n",
      "Epoch 82: Training Loss: 0.010\n",
      "14900\n",
      "15000\n",
      "Epoch 83: Training Loss: 0.010\n",
      "15100\n",
      "15200\n",
      "Epoch 84: Training Loss: 0.011\n",
      "15300\n",
      "Epoch 85: Training Loss: 0.009\n",
      "15400\n",
      "15500\n",
      "Epoch 86: Training Loss: 0.012\n",
      "15600\n",
      "15700\n",
      "Epoch 87: Training Loss: 0.012\n",
      "15800\n",
      "15900\n",
      "Epoch 88: Training Loss: 0.011\n",
      "16000\n",
      "16100\n",
      "Epoch 89: Training Loss: 0.013\n",
      "16200\n",
      "Epoch 90: Training Loss: 0.013\n",
      "16300\n",
      "16400\n",
      "Epoch 91: Training Loss: 0.015\n",
      "16500\n",
      "16600\n",
      "Epoch 92: Training Loss: 0.011\n",
      "16700\n",
      "16800\n",
      "Epoch 93: Training Loss: 0.013\n",
      "16900\n",
      "17000\n",
      "Epoch 94: Training Loss: 0.010\n",
      "17100\n",
      "Epoch 95: Training Loss: 0.010\n",
      "17200\n",
      "17300\n",
      "Epoch 96: Training Loss: 0.011\n",
      "17400\n",
      "17500\n",
      "Epoch 97: Training Loss: 0.009\n",
      "17600\n",
      "17700\n",
      "Epoch 98: Training Loss: 0.008\n",
      "17800\n",
      "Epoch 99: Training Loss: 0.009\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(resnet34.parameters(),lr = 0.001, betas = (0.9,0.999))\n",
    "loss_metric = nn.L1Loss()\n",
    "n_epochs = 100\n",
    "iteration = 0\n",
    "for e in range(n_epochs):\n",
    "    losses = []\n",
    "    for batch_input, batch_labels in dataloader:\n",
    "        if iteration % 100 == 0:\n",
    "            print(iteration)\n",
    "        # make sure to zero out gradient\n",
    "        resnet34.zero_grad()\n",
    "        \n",
    "        # move to gpu + get correct labels\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_labels = label_mapping_scaled[batch_labels].to(device)\n",
    "        \n",
    "        loss = loss_metric(resnet34(batch_input),batch_labels)\n",
    "        losses.append(loss.data)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        iteration += 1\n",
    "#         break\n",
    "    print(\"Epoch %d: Training Loss: %0.3f\" % (e,np.mean(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5089547997389491],\n",
    "                                     std=[1])])\n",
    "valImages = datasets.ImageFolder(root='./validation',transform = data_transform)\n",
    "label_mapping_v = torch.FloatTensor([float(clazz) for clazz in valImages.classes])\n",
    "\n",
    "# label_mapping\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1905.,  1906.,  1908.,  1909.,  1910.,  1911.,  1912.,  1913.,\n",
       "         1914.,  1915.,  1916.,  1919.,  1922.,  1923.,  1924.,  1925.,\n",
       "         1926.,  1927.,  1928.,  1929.,  1930.,  1931.,  1932.,  1933.,\n",
       "         1934.,  1935.,  1936.,  1937.,  1938.,  1939.,  1940.,  1941.,\n",
       "         1942.,  1943.,  1944.,  1945.,  1946.,  1947.,  1948.,  1949.,\n",
       "         1950.,  1951.,  1952.,  1953.,  1954.,  1955.,  1956.,  1957.,\n",
       "         1958.,  1959.,  1960.,  1961.,  1962.,  1963.,  1964.,  1965.,\n",
       "         1966.,  1967.,  1968.,  1969.,  1970.,  1971.,  1972.,  1973.,\n",
       "         1974.,  1975.,  1976.,  1977.,  1978.,  1979.,  1980.,  1981.,\n",
       "         1982.,  1983.,  1984.,  1985.,  1986.,  1987.,  1988.,  1989.,\n",
       "         1990.,  1991.,  1992.,  1993.,  1994.,  1995.,  1996.,  1997.,\n",
       "         1998.,  1999.,  2000.,  2001.,  2002.,  2003.,  2004.,  2005.,\n",
       "         2006.,  2007.,  2008.,  2009.,  2010.,  2011.,  2012.,  2013.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1933.,  1935.,  1936.,  1940.,  1944.,  1945.,  1946.,  1947.,\n",
       "         1949.,  1950.,  1951.,  1952.,  1954.,  1955.,  1959.,  1961.,\n",
       "         1962.,  1963.,  1965.,  1967.,  1968.,  1970.,  1972.,  1973.,\n",
       "         1975.,  1976.,  1977.,  1978.,  1979.,  1981.,  1983.,  1984.,\n",
       "         1990.,  1991.,  1992.,  2000.,  2001.,  2002.,  2005.,  2008.,\n",
       "         2011.,  2012.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_scaled_v = (label_mapping_v - label_mapping.min())/(label_mapping.max() - label_mapping.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0253,  0.0380,  0.0886,  0.1392,  0.1519,  0.1646,\n",
       "         0.1772,  0.2025,  0.2152,  0.2278,  0.2405,  0.2658,  0.2785,\n",
       "         0.3291,  0.3544,  0.3671,  0.3797,  0.4051,  0.4304,  0.4430,\n",
       "         0.4684,  0.4937,  0.5063,  0.5316,  0.5443,  0.5570,  0.5696,\n",
       "         0.5823,  0.6076,  0.6329,  0.6456,  0.7215,  0.7342,  0.7468,\n",
       "         0.8481,  0.8608,  0.8734,  0.9114,  0.9494,  0.9873,  1.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping_scaled_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valDataloader = torch.utils.data.DataLoader(valImages,batch_size = 128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046557505\n"
     ]
    }
   ],
   "source": [
    "# to turn off running averages in batch norm\n",
    "resnet34.eval()\n",
    "losses = []\n",
    "for batch_input,batch_labels in valDataloader:\n",
    "    batch_input = batch_input.to(device)\n",
    "    batch_labels = label_mapping_scaled_v[batch_labels].to(device)\n",
    "    res = resnet34(batch_input)\n",
    "#     print(res)\n",
    "#     print(batch_labels)\n",
    "    loss = loss_metric(res,batch_labels)\n",
    "#     print(loss.data)\n",
    "    losses.append(loss.data)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.1226, device='cuda:0'), tensor(0.1452, device='cuda:0'), tensor(0.1358, device='cuda:0'), tensor(0.1300, device='cuda:0'), tensor(0.1321, device='cuda:0'), tensor(0.1246, device='cuda:0'), tensor(0.1419, device='cuda:0'), tensor(0.1292, device='cuda:0'), tensor(0.1356, device='cuda:0'), tensor(0.1464, device='cuda:0'), tensor(0.1410, device='cuda:0'), tensor(0.1308, device='cuda:0'), tensor(0.1389, device='cuda:0'), tensor(0.1282, device='cuda:0'), tensor(0.1357, device='cuda:0'), tensor(0.1299, device='cuda:0'), tensor(0.1335, device='cuda:0'), tensor(0.1398, device='cuda:0'), tensor(0.1365, device='cuda:0'), tensor(0.1391, device='cuda:0'), tensor(0.1293, device='cuda:0'), tensor(0.1508, device='cuda:0'), tensor(0.1500, device='cuda:0'), tensor(0.1600, device='cuda:0'), tensor(0.1442, device='cuda:0'), tensor(0.1385, device='cuda:0'), tensor(0.1298, device='cuda:0'), tensor(0.1410, device='cuda:0'), tensor(0.1505, device='cuda:0'), tensor(0.1444, device='cuda:0'), tensor(0.1373, device='cuda:0'), tensor(0.1384, device='cuda:0'), tensor(0.1460, device='cuda:0'), tensor(0.1304, device='cuda:0'), tensor(0.1338, device='cuda:0'), tensor(0.1299, device='cuda:0'), tensor(0.1264, device='cuda:0'), tensor(0.1430, device='cuda:0'), tensor(0.1366, device='cuda:0'), tensor(0.1380, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2785,  0.8608,  0.8481,  0.7468,  0.3291,  0.2152,  0.4304,\n",
       "         0.3797,  0.5823,  0.1392,  0.7468,  0.5443,  0.0380,  0.2785,\n",
       "         0.4684,  0.4430,  0.6076], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
