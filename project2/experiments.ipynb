{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.utils.data as data\n",
    "from utils import *\n",
    "from models import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "]) \n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "dataloader = datasets.CIFAR10\n",
    "batch_size = 64\n",
    "test_bs = 256\n",
    "\n",
    "trainset = dataloader(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = dataloader(root='./data', train=False, download=True,\n",
    "        transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=test_bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "lr = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lambda_TV = 1e-4\n",
    "layer_mask = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without TV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, testloader):\n",
    "    model.eval()\n",
    "    class_losses = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch_input, batch_labels in testloader:\n",
    "            batch_input = batch_input.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            batch_output = model(batch_input)\n",
    "            batch_pred = torch.argmax(batch_output, dim = 1)\n",
    "            acc = torch.mean(torch.eq(batch_pred,batch_labels).type(torch.float))\n",
    "            class_loss = criterion(batch_output,batch_labels)\n",
    "            \n",
    "            accs.append(acc.item())\n",
    "            class_losses.append(class_loss.item())\n",
    "    return np.mean(accs),np.mean(class_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Test Acc:   0.1021 | Test Loss:   2.3026 | Train loss:   1.8410 | Init TV: 1043.0659\n",
      "Epoch 1 | Test Acc:   0.3868 | Test Loss:   1.6481 | Train loss:   1.5636 | Init TV: 1104.4001\n",
      "Epoch 2 | Test Acc:   0.4708 | Test Loss:   1.4891 | Train loss:   1.4197 | Init TV: 1174.3119\n",
      "Epoch 3 | Test Acc:   0.5138 | Test Loss:   1.3320 | Train loss:   1.3369 | Init TV: 1248.3767\n",
      "Epoch 4 | Test Acc:   0.5326 | Test Loss:   1.2915 | Train loss:   1.2899 | Init TV: 1316.1458\n",
      "Epoch 5 | Test Acc:   0.5582 | Test Loss:   1.2257 | Train loss:   1.2471 | Init TV: 1384.0524\n",
      "Epoch 6 | Test Acc:   0.5603 | Test Loss:   1.2287 | Train loss:   1.2112 | Init TV: 1450.5839\n",
      "Epoch 7 | Test Acc:   0.5486 | Test Loss:   1.2437 | Train loss:   1.1870 | Init TV: 1515.5562\n",
      "Epoch 8 | Test Acc:   0.5805 | Test Loss:   1.2078 | Train loss:   1.1562 | Init TV: 1577.9421\n",
      "Epoch 9 | Test Acc:   0.5949 | Test Loss:   1.1597 | Train loss:   1.1299 | Init TV: 1634.8892\n",
      "Epoch 10 | Test Acc:   0.5806 | Test Loss:   1.1835 | Train loss:   1.1095 | Init TV: 1690.1689\n",
      "Epoch 11 | Test Acc:   0.5883 | Test Loss:   1.1446 | Train loss:   1.0905 | Init TV: 1750.6021\n",
      "Epoch 12 | Test Acc:   0.6019 | Test Loss:   1.1549 | Train loss:   1.0756 | Init TV: 1803.8844\n",
      "Epoch 13 | Test Acc:   0.5919 | Test Loss:   1.1454 | Train loss:   1.0572 | Init TV: 1854.4563\n",
      "Epoch 14 | Test Acc:   0.6044 | Test Loss:   1.1245 | Train loss:   1.0506 | Init TV: 1906.9331\n",
      "Epoch 15 | Test Acc:   0.6031 | Test Loss:   1.1338 | Train loss:   1.0247 | Init TV: 1954.3844\n",
      "Epoch 16 | Test Acc:   0.6058 | Test Loss:   1.1329 | Train loss:   1.0191 | Init TV: 2009.4381\n",
      "Epoch 17 | Test Acc:   0.6163 | Test Loss:   1.1115 | Train loss:   1.0127 | Init TV: 2057.6702\n",
      "Epoch 18 | Test Acc:   0.6128 | Test Loss:   1.1012 | Train loss:   1.0013 | Init TV: 2104.7908\n",
      "Epoch 19 | Test Acc:   0.6180 | Test Loss:   1.1012 | Train loss:   0.9914 | Init TV: 2151.8398\n",
      "Epoch 20 | Test Acc:   0.6205 | Test Loss:   1.1010 | Train loss:   0.9857 | Init TV: 2194.2812\n",
      "Epoch 21 | Test Acc:   0.6232 | Test Loss:   1.0649 | Train loss:   0.9732 | Init TV: 2246.5293\n",
      "Epoch 22 | Test Acc:   0.6173 | Test Loss:   1.0940 | Train loss:   0.9686 | Init TV: 2291.7124\n",
      "Epoch 23 | Test Acc:   0.6284 | Test Loss:   1.0738 | Train loss:   0.9565 | Init TV: 2334.9849\n",
      "Epoch 24 | Test Acc:   0.6236 | Test Loss:   1.0795 | Train loss:   0.9452 | Init TV: 2378.0430\n",
      "Epoch 25 | Test Acc:   0.6296 | Test Loss:   1.0834 | Train loss:   0.9383 | Init TV: 2422.6326\n",
      "Epoch 26 | Test Acc:   0.6336 | Test Loss:   1.0629 | Train loss:   0.9301 | Init TV: 2468.1404\n",
      "Epoch 27 | Test Acc:   0.6275 | Test Loss:   1.0787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7d801ed5fdb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTVLossMat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensor is not a torch image.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    # validation\n",
    "    val_acc, val_loss = eval_model(model,testloader)\n",
    "    print(\"Epoch\", e, \"| Test Acc:\", \"{:8.4f}\".format(val_acc), \"| Test Loss:\", \"{:8.4f}\".format(val_loss), end = \"\")\n",
    "    \n",
    "    # training\n",
    "    model.train()\n",
    "    class_losses = []\n",
    "    TV_losses = []\n",
    "    ok = 0\n",
    "    with torch.no_grad():\n",
    "        init = TVLossMat(model, layer_mask).item()\n",
    "    for batch_input, batch_labels in trainloader:\n",
    "        optim.zero_grad()\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        batch_output = model(batch_input)\n",
    "        \n",
    "        class_loss = criterion(batch_output,batch_labels)\n",
    "        loss = class_loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        class_losses.append(class_loss.item())\n",
    "    print(\" | Train loss:\", \"{:8.4f}\".format(np.mean(class_losses)), \"| Init TV:\", \"{:8.4f}\".format(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=10).to(device)\n",
    "EPOCHS = 25\n",
    "lr = 1e-3\n",
    "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lambda_TV = 1e-4\n",
    "layer_mask = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Test Acc:   0.0977 | Test Loss:   2.3027 | Train loss:   1.8552 | Init TV: 1039.3700 | TV loss:   0.0365\n",
      "Epoch 1 | Test Acc:   0.3759 | Test Loss:   1.5947 | Train loss:   1.5559 | Init TV: 282.5186 | TV loss:   0.0296\n",
      "Epoch 2 | Test Acc:   0.4462 | Test Loss:   1.5486 | Train loss:   1.4050 | Init TV: 314.3334 | TV loss:   0.0338\n",
      "Epoch 3 | Test Acc:   0.5090 | Test Loss:   1.3243 | Train loss:   1.3135 | Init TV: 359.6890 | TV loss:   0.0377\n",
      "Epoch 4 | Test Acc:   0.5545 | Test Loss:   1.2513 | Train loss:   1.2425 | Init TV: 393.9750 | TV loss:   0.0410\n",
      "Epoch 5 | Test Acc:   0.5740 | Test Loss:   1.2051 | Train loss:   1.1993 | Init TV: 428.5070 | TV loss:   0.0440\n",
      "Epoch 6 | Test Acc:   0.5754 | Test Loss:   1.1829 | Train loss:   1.1580 | Init TV: 449.0258 | TV loss:   0.0464\n",
      "Epoch 7 | Test Acc:   0.5953 | Test Loss:   1.1479 | Train loss:   1.1213 | Init TV: 470.5056 | TV loss:   0.0485\n",
      "Epoch 8 | Test Acc:   0.6149 | Test Loss:   1.1060 | Train loss:   1.0957 | Init TV: 494.7659 | TV loss:   0.0504\n",
      "Epoch 9 | Test Acc:   0.6063 | Test Loss:   1.1527 | Train loss:   1.0702 | Init TV: 514.0292 | TV loss:   0.0524\n",
      "Epoch 10 | Test Acc:   0.6219 | Test Loss:   1.1017 | Train loss:   1.0408 | Init TV: 531.0237 | TV loss:   0.0540\n",
      "Epoch 11 | Test Acc:   0.6287 | Test Loss:   1.0742 | Train loss:   1.0178 | Init TV: 547.2469 | TV loss:   0.0555\n",
      "Epoch 12 | Test Acc:   0.6136 | Test Loss:   1.0995 | Train loss:   1.0059 | Init TV: 559.1769 | TV loss:   0.0568\n",
      "Epoch 13 | Test Acc:   0.6256 | Test Loss:   1.1055 | Train loss:   0.9870 | Init TV: 573.2368 | TV loss:   0.0585\n",
      "Epoch 14 | Test Acc:   0.6400 | Test Loss:   1.0615 | Train loss:   0.9647 | Init TV: 589.6305 | TV loss:   0.0597\n",
      "Epoch 15 | Test Acc:   0.6079 | Test Loss:   1.1355 | Train loss:   0.9496 | Init TV: 603.4634 | TV loss:   0.0610\n",
      "Epoch 16 | Test Acc:   0.6406 | Test Loss:   1.0683 | Train loss:   0.9401 | Init TV: 613.5420 | TV loss:   0.0619\n",
      "Epoch 17 | Test Acc:   0.6445 | Test Loss:   1.0417 | Train loss:   0.9259 | Init TV: 620.4852 | TV loss:   0.0628\n",
      "Epoch 18 | Test Acc:   0.6383 | Test Loss:   1.0392 | Train loss:   0.9140 | Init TV: 635.0947 | TV loss:   0.0639\n",
      "Epoch 19 | Test Acc:   0.6480 | Test Loss:   1.0183 | Train loss:   0.9026 | Init TV: 646.2944 | TV loss:   0.0651\n",
      "Epoch 20 | Test Acc:   0.6421 | Test Loss:   1.0516 | Train loss:   0.8914 | Init TV: 655.1609 | TV loss:   0.0663\n",
      "Epoch 21 | Test Acc:   0.6592 | Test Loss:   1.0077 | Train loss:   0.8804 | Init TV: 668.0795 | TV loss:   0.0673\n",
      "Epoch 22 | Test Acc:   0.6589 | Test Loss:   0.9939 | Train loss:   0.8724 | Init TV: 679.1730 | TV loss:   0.0686\n",
      "Epoch 23 | Test Acc:   0.6508 | Test Loss:   1.0241 | Train loss:   0.8580 | Init TV: 687.0673 | TV loss:   0.0692\n",
      "Epoch 24 | Test Acc:   0.6615 | Test Loss:   0.9992 | Train loss:   0.8535 | Init TV: 697.9909 | TV loss:   0.0702\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    # validation\n",
    "    val_acc, val_loss = eval_model(model,testloader)\n",
    "    print(\"Epoch\", e, \"| Test Acc:\", \"{:8.4f}\".format(val_acc), \"| Test Loss:\", \"{:8.4f}\".format(val_loss), end = \"\")\n",
    "    \n",
    "    # training\n",
    "    model.train()\n",
    "    class_losses = []\n",
    "    TV_losses = []\n",
    "    with torch.no_grad():\n",
    "        init = TVLossMat(model, layer_mask).item()\n",
    "    for batch_input, batch_labels in trainloader:\n",
    "        optim.zero_grad()\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        batch_output = model(batch_input)\n",
    "        \n",
    "        class_loss = criterion(batch_output,batch_labels)\n",
    "        TV_loss = TVLossMat(model, layer_mask)\n",
    "        loss = class_loss + lambda_TV*TV_loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        class_losses.append(class_loss.item())\n",
    "        TV_losses.append(TV_loss.item()*lambda_TV)\n",
    "    \n",
    "    print(\" | Train loss:\", \"{:8.4f}\".format(np.mean(class_losses)), \"| Init TV:\", \"{:8.4f}\".format(init), \"| TV loss:\", \"{:8.4f}\".format(np.mean(TV_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
